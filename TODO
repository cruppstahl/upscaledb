
I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x rewrite samples with new coding style

x rewrite tools with new coding style

x rewrite c++ API with new coding style

x clean up the "close" functions
    x get rid of the "private" bit in the Database (DB_ENV_IS_PRIVATE)
    x ham_close - move all functionality to Database::close
    x ham_env_close - move all functionality to Environment::close
    x ~Database: call close(), then simplify all code
    x ~Environment: call close(), then simplify all code
    x Cursor::close: currently (nearly) empty; merge with ~Cursor and
        Database::close_cursor()
    x do not have st2/st; just fail if there's a serious problem

    x support scenarios like
        ham_env_close(env, 0);
        ham_close(db, 0);
    x test with c++ api unittests

x clean up APIs
    x Remove AES encryption
      Remove including all file filters, 3rdparty, dotnet, java, win32
    x Remove zlib compression
      Remove including all record filters, 3rdparty, dotnet, java, win32
    x Remove unittests/filter.cpp
    x Remove ham_get_keycount_per_page (make available through other function?)
    x Remove ham_calc_maxkeys_per_page
    x Remove other stuff from hamsterdb_int.h
    x Get rid of sorted duplicates
    x Do you use any of the HAM_HINT_* flags?
      Yes, leave APPEND and PREPEND; check when they are used. are they really
        needed? the histogram should do that automatically
    x Remove the DAM flags
      DAM is currently used to decide about split point; really necessary? The
      hinter should do this automatically
    x clean up ham_flush, ham_env_flush
    x rename HAM_WRITE_THROUGH to HAM_ENABLE_FSYNC
    x rename ham_cursor_find_ex to ham_cursor_find
    x clean up ham_get_parameters, ham_env_get_parameters, ham_get_flags
        x ham_get_parameters and ham_env_get_parameters should not
            allow the use of the same parameters
        x remove ham_get_flags since it's obsolete
    x once more check all flags and #defines; remove deprecated and obsolete
        stuff (i.e. HAM_LOCK_EXCLUSIVE)
        HAM_DISABLE_FREELIST_FLUSH
        HAM_LOCK_EXCLUSIVE
        HAM_IN_MEMORY_DB
    x rename ham_env_open_ex to ham_env_open
    x rename ham_env_create_ex to ham_env_create
    x HAM_DB_READ_ONLY -> HAM_READ_ONLY (or would this get a conflict)
    x remove ham_open[_ex]
    x remove ham_create[_ex]
    x remove ham_new, ham_env_new, ham_delete, ham_env_delete
        x fix tools
        x fix samples
        x fix unittests
        x also delete db->set_active, env->set_active
        x also clean up PRIVATE flag
        x fix java api
        x fix dotnet api
    x prefix all database functions with ham_db_*
    x review all interfaces whether they consequently sort parameters
    x remove the HINT flags in hamsterdb_int.h
        HAM_HINT_UBER_FAST_ACCESS
        HAM_HINT_RANDOM_ACCESS
        HAM_HINT_SEQUENTIAL

x improve fsync performance; do not fsync in Journal::abort. 

x btree_insert.cc:120: the append/prepend logic does not work

x DatabaseImplementation: get rid of these, they are no longer required
    with the new API. 
    x have an abstract Database
    x derive LocalDatabase
    x derive RemoteDatabase
    x remove dam_is_set
    x merge cursor_clone and clone_cursor
    x merge close_cursor and cursor_close
    x clean up code
    x rewrite db_get_keysize() as db->get_keysize()
    x review header page ownership; it's currently assigned when creating
        a new database - already removed
    x remove linked list of Databases; use std::map<short, db> instead
    x search env.cc for "TODO why?"
    x remove static/global functions
        x remove ONLY_FROM_CACHE

x review usage of mmap; when opening, should we just map the whole file into
    memory (in a single mmap)? when creating the file then os_mmap anyway
    should never be called
    x merge the Device classes: Device (abstract), DiskDevice, MemoryDevice
    x Page::free: do not unmap and do not move to cache if it's mmapped!
    x Environment: do not fallback to read/write if mmap fails
    x what is the flag DB_USE_MMAP good for?? - removed
    x when trying to figure out if mmap can be used (ham_env_open):
        just try it. if it fails then fallback to r/w
    x support HAM_DISABLE_MMAP
    x DiskDevice::open: map the whole file; if this fails: fallback to r/w
        check all supported platforms: what happens if we map a file that
        is not aligned? we have to extend the map!
    x can we remove os_get_pagesize()?
    x DiskDevice::close: unmap immediately before closing the device
    x DiskDevice::read_page: if page is mapped then simply return a
        pointer; do not fallback to r/w. Make sure that we do not read past
        the map!
    x Database.cc:__cache_needs_purge: move to Database, adjust?
    x Cache::too_big(): must ignore mapped pages
    x Cache::purge_max20: do not purge mmapped caches
    x some unittests are failing
    x compare performance to previous mmap implementation
      2.0.5 vs 2.0.6: 1.2 GB Database file, 2 million items (w/ duplicates)
        real    1m28.088s
        user    0m9.425s
        sys 1m17.957s

        real    1m0.222s
        user    0m11.633s
        sys 0m48.107s
    x the implementation of Cache::purge is bad. get_unused() always traverses
        the cache's list from tail to head. can this be improved? i.e. by
        calling the callback function from get_unused_page(), and merge
        purge_max20 with get_unused_page?
    x update unittests

x need the ham_export tool in THIS release - and make sure that it's linked
    statically!!!
    x export as binary (based on protobuffer - this is the default)
    x support these switches:
        ham_export --help
        ham_export <env>       # dumps to stdout
        ham_export --output=file <env> # dumps to file
    x make sure this links statically against hamsterdb!
    x do not build ham_export if protobuffer is not installed

x merge Automake patch from Daniel (see email)

x ham_import: a tool that can create Environments from exported data
    (or merge into existing Environments)
    x do not build ham_import if protobuffer is not installed
    x support these switches:
        ham_import --help
        ham_import --stdin <database> # reads from stdin
        ham_import <dump-file> <database>   # fails if db already exists
        ham_import <dump-file> --merge <database> # merges into database
    x need tests for the whole ham_export/ham_import flow; simply use
        ham_info -f or ham_dump on source and destination database, then compare
        (or use .golden file)
        x with multiple databases - env1.c
        x with duplicates - env3.c
        x with extended keys
        x merge into existing database: extkeys.db in env3.db
    x write errors to stderr, not stdout
        x also for ham_export
    x print statistics when done (number of databases, number of keys)
        x also for ham_export

x remove HAM_FAST_ESTIMATE?! or rename to HAM_IGNORE_DUPLICATES?

x remove backend.h, directly use BtreeBackend
    x remove virtual functions
    x remove m_is_active
    x remove flush_indexdata or make private?
    x rename to BtreeIndex
    x clean up btree.h, remove some of the TODOs
    x the whole btree backend should use a LocalDatabase instead of a
        Database pointer
    x clean up db.h, remove some of the TODOs

x clean up db_indexdata_t and related functions
    x rename to BtreeDescriptor
    x Btree::create: call index_set_name()
    x move to Btree
    x remove cached RecordNumber -- already removed
    x combine Btree::flush_metadata with Btree::set_rootpage, remove
        flush_metadata
    x run unittests, some are failing/asserting

x Remove HAM_USE_BTREE

x adjust monster.sh
    x need changes for the new API
        x remove HAM_DAM*
        x remove aes encryption, compression
        x remove sort-duplicates
        x remove HAM_HINT_RANDOM_ACCESS, HAM_HINT_SEQUENTIAL,
            HAM_HINT_UBER_FAST_ACCESS
        x remove HAM_LOCK_EXCLUSIVE
    x re-enable mmap with threads in monster.sh
    x re-enable the memory allocator
    x refactor code, code formatting

x Remove HAM_LOCK_EXCLUSIVE

x Rename ham_check_integrity -> ham_db_check_integrity

x write extra documentation about getting the best performance
    x reduce keys/records as much as possible
    x play around with keysize/pagesize
    x increase cache size
    x use mmap when opening files, but be aware of the problems
    x transactions: use HAM_OVERWRITE
    x transactions: store log/journal on different disk

x split Environment into baseclass, derive local and remote Environment
    x remove function pointers
    x move curl handle into RemoteEnvironment
    x remote.cc: remove static functions
    x env.cc: clean up code
    x remote.cc: clean up code
    x env.cc: remove static functions
    x move db_flush_all into LocalEnvironment
    x move db_fetch_page_impl to Environment
    x move db_alloc_page_impl to Environment
    x try to reduce the TODOs
    x get rid of __check_create_parameters

x Remove HAM_NOT_INITIALIZED

x cleanup ham/types.h
    x use stdint.h/inttypes.h
    x get rid of ham_offset_t

x rename namespace "ham" to "hamsterdb"
    x also for C++ API

x hamsterdb refactoring, reformatting
    x reformat the sources, clean up the code
    x ham_env_create: __check_create_parameters
    x ham_env_open: __check_create_parameters
    x try to get rid of HAM_DONT_LOCK
    x try to reduce the TODOs
    x review usage of HAM_HINT_*: should we allow/document them? - leave as is

x add transaction support for in-memory databases
    x create unittests for all txn-related functions
        x insert
        x erase
        x find
        x cursor_insert
        x cursor_find
        x cursor_erase
        x cursor_get_duplicate_count
        x cursor_get_record_size
        x cursor_overwrite
    x change/update the code
    x change/update the documentation in the header file
    x change/update the changelog

x refactoring of txn_cursor_t
    x rename to TransactionCursor
    x get proper class and methods

x refactoring of cursor.h/cursor.cc

x txn_cursor.cc still has static functions

x refactoring of txn.h/txn.cc
    x txn_op_t -> TransactionOperation
    x txn_opnode_t -> TransactionNode
    x txn_optree_t -> TransactionIndex

x disallow usage of extended keys UNLESS HAM_ENABLE_EXTENDED_KEYS is active
    x add to header file
    x check in ham_db_insert
        x unittest
    x check in ham_cursor_insert
        x unittest
    x flag must be persisted
    x add to java API
    x add to dotnet API
    x document this

o need a launchpad project; start with 12.04 for 64bit
    sudo apt-get install packaging-dev dh-make
    <migrate gpg key>
    <migrate ssh key>
    pbuilder-dist precise create
    pbuilder-dist quantal create
    bzr whoami "Christoph Rupp <chris@crupp.de>"
    bzr launchpad-login 9e9o1ko8b2f5xpiibgscjzlhug6x9-chris
  add to ~/.bashrc:
    export DEBFULLNAME="Christoph Rupp"
    export DEBEMAIL="chris@crupp.de"
    http://www.quietearth.us/articles/2006/08/16/Building-deb-package-from-source
    http://www.webupd8.org/2010/01/how-to-create-deb-package-ubuntu-debian.html
    http://developer.ubuntu.com/packaging/html/packaging-new-software.html

o finalize for the next release
    x version is 2.1.0!!
    x increment libtool version
    x sources: change copyright date to 2013
    x webpage: change copyright date to 2013
    o run valgrind tests
    o update README w/ API updates
    o update Webpage w/ API updates
    o update Wiki w/ API updates ("migration guide")
    o update FAQ/Documentation regarding mmap
    o need documentation for ham_export, ham_import
    o MSVC project files for ham_import, ham_export

. can we perform better with O_DIRECT? run some benchmarks

o continue refactoring of txn.h/txn.cc
    o TransactionIndex: use std::set<OperationNode> instead of rb.h
    o try to cleanup the flow; move more code from db.cc to txn.cc,
        reorg TransactionIndex similar to BtreeIndex
    o try to replace some of the linked lists with boost::intrusive_list
    o document the tree structure in the header file

------------------- release 2.0.6 -----------------------------------------













o freelist rewrite - make files smaller, make hamsterdb faster
    o freelist.h
    o freelist.cc
    o freelist_statistics.h
    o freelist_statistics.cc
        ==> get rid of the whole freelist; no need to refactor the existing
            code
        ==> described in github wiki
        ==> need a migration path (i.e. allow forward-cursors if db is
            read-only, no transactions)
    o need migration path:
        o ham_dump: rename to ham_export, write json or protobuf
        o ham_import: read from file or stdin; either merge into or overwrite
            an existing file or create a new file
        o ham_export test.db | ham_import test2.db --stdin
    o also adjust file format for the upcoming btree changes!

o preallocate file space
    pages should be optimized in a way that the growing index will be written
    sequentially

o should database names still be reserved?

. also remove locking from C# and Java APIs

. write a custom memory allocator, based on 4kb pages
    if memory is allocated: pick the current page; if it has enough free space
    then return a pointer and decrease the amount of free space.
    If memory is freed than increase the amount of freed memory. If this amount
    == 4kb then the page is stored in a lookaside-list and will be used later.
    If the page does not have enough memory for alloc then either fetch
    another free page from the lookaside-list or allocate a new one.
    o use this in the TransactionTree to avoid small allocations

o continue with refacoring - indention, coding style, better design etc...
    o unittests
        x code formatting
        o reduce bfc to a single header file, or use boost unittest framework
            http://www.boost.org/doc/libs/1_35_0/libs/test/doc/components/utf/index.html
            http://www.beroux.com/english/articles/boost_unit_testing/
            http://www.alittlemadness.com/2009/03/31/c-unit-testing-with-boosttest/

    o get rid of ham_bool_t, replace with bool whenever possible

o split Transaction into local and remote class
    o hamsterdb.cc directly calls into Transaction class instead of Environment
    o then continue with db.cc and move txn-related functions to LocalDatabase
    o try to get the methods/design analoguous to the Btree
    o TransactionIndex:
        x check how/if std::multimap can replace rb.h - yes, seems to work
        o replaces the TransactionTree
        o one TransactionIndex per Database (always created)
        o remove rb.h
        o txn_opnode_t -> TransactionOperation
        o txn_node_t is no longer required
        o try to move code from db.cc into TransactionIndex, i.e. to check
            conflicts etc
        o is a std::multimap<ham_key_t, operation)
        . use a custom allocator for all TransactionOperations of a single
            Transaction
        . use a custom allocator for std::multimap

o split Cursor into local and remote class
    o hamsterdb: directly call into Cursor class (instead of Database)

o fix usage of DB_NEW_PAGE_DOES_THRASH_CACHE

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset? that way we would avoid the frequent syncs
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o is the recovery working if there's a crash during ham_close?

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

. track additional metrics
    o cache misses
    o cache hits
    o ...

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o btree_cursor.h/btree_cursor.cc
    o use memory arena for uncoupling the key

o python API - update and integrate
    o rewrite with boost::python??
    o also add to win32 package

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurÃ¼ckgeben?
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

o recovery: re-create pending transactions (if required)
    o needs a function to enumerate them

o allow transactions in-memory

o allow transactions w/o journal

o allow transactions w/o recovery

. android port (needs new java api) in /contrib directory (it's on a separate
    branch)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. look for someone who can write a PHP or Perl or Ruby wrapper

. implement support for partial keys

. test with tcmalloc; if it works then also use it in the master branch, but
    make sure that memory consumption does not increase significantly

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. hash-table.h: the foreach/remove_if/visitor pattern is clumsy. use
    functor or class w/ operator() instead
. changeset: use a generic hash table for fast lookup (but leave list in place
    for everything else)
. cache: use a generic hash table

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. the whole c++ protocol should be c++-ified

. move the whole configuration (key sizes, parameters, page size, etc) into a
    separate class which is instantiated by the env

. c++-ify the btree node representation;
    o include duplicates as well! disentangle duplicates from blob-handling

. c++-ify the blob handling and split off the duplicates

. cleanup db.h/db.cc - move functions into Database or
    DatabaseImplementationLocal namespace - but take care b/c these functions
    are also used by Cursor or other modules which don't necessarily have
    access to the Local stuff
    o db_get_key_count
    o db_alloc_page
    o db_fetch_page
    o db_insert_txn
    o db_erase_txn
    o db_find_txn
    o db_check_insert_conflicts
    o db_check_erase_conflicts
    o __increment_dupe_index

. c++-ify everything else

. device, page and os shold no longer return errors but throw exceptions

XXXXXXXXXXXXXXXXXXXXX release 2.0.0 STABLE !!! XXXXXXXXXXXXXXXXXXXXXXXXXXXXX

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the blob, not
    to the log. the log will only contain the rid.
    o document this (and also the drawback - that an abort will lose the
        blobs and they cannot be reused
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

o hamsterdb.com
    x add twitter feed
    o API documentation: don't link to "modules" but to startup page, update
        with newest version
    o crupp.de: do a backup of the database
    . google +1 button
    . can we use something like Aller.font?

o update documentation
    x in header file
    o in the wiki
        o don't forget to list all functions that are currently disabled
            w/ txn's -> sorting dupes, approx. matching, ...
        o transactional behavior/conflicts of duplicate keys
    o in the wiki: start with internal documentation
        o transactions
        o architecture
        o btree
        o journal/log
        o cache
        o I/O
        o unittests
        o cursor(s)
        o monstertests - how to use them?

o fully (!) automize the whole release process for unix; the result (on
    success) are the following files:
    o tar-ball
    o the README
    o the documentation as a tar
    o the Changelog
    o the release notes (a template)
    o the output (xml) of the monster tests

. port to WinCE

o how can we extend the monster-tests to have reliable tests for transactions?

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created

o extkeys: don't use txn_id for the 'age', use lsn instead

o the DatabaseImplementation subclass is not neccessary; all subclasses
    can directly derive from Database.

. allow use of transactions without a log/journal

. allow use of transactions for in-memory databases

XXXXXXXXXXXXXXXXXXXXX release 2.0.0 STABLE XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

o ham_get_count: could be atomically updated with every journal entry

o when flushing a changeset: sort by offset, use writev()

o add concurrency (on a high level)

o flush transactions in background

. have a flag to disable flushing of logfiles/journal files (or flush them
    async.)

o continue as described in integrate-ham2.txt...

