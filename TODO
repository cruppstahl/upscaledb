I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x win32: get rid of boost_thread

x boost: configure script should make sure that only boost v 1.46 (or newer)
    is accepted
    -> also test with older versions, but 1.33 definitely does not work
    issue #17: https://github.com/cruppstahl/hamsterdb/issues/17

x metrics: add extkey_cache:hits, :misses

x AES encryption
    x create a test program which encrypts/decrypts data (cbc)
        http://saju.net.in/code/misc/openssl_aes.c.txt
    x ./configure: enable aes by default if -lcrypto is available
    x ./configure: add new option "--disable-encryption"
    x move prototype to .cc file
    x create header file documentation; HAM_PARAM_ENCRYPTION_KEY is a
        16byte array with the key
    x ham_env_create: new option HAM_PARAM_ENCRYPTION_KEY enables encryption
        x do not allow if in-memory 
            x unittest
        x disable mmap if encryption is enabled
            x unittest
    x ham_env_open: new option HAM_PARAM_ENCRYPTION_KEY
        x add unittests for create/open, test good and bad keys
        x disable mmap if encryption is enabled
            x unittest
    x disable direct I/O
    x encrypt/decrypt pages
        x cbc-encrypted with page-id as salt
        x need tests w/ reopen, inserts (growing size, 1 - 512 bytes)
    x encrypt/decrypt the log (everything is already padded)
        x do not use salt
        x need tests w/ recovery
        x also test in recovery.pl
    x add to monster tests
    x extend the Windows build

x clean up Database class
    x split into multiple files
    x remove the TODOs
    x refactor, reformat if necessary
    x db_local.cc has many static functions; remove them

x clean up Cursors
    x different definitions of Page::uncouple_cursor,
        BtreeIndex::uncouple_cursor, btree_uncouple_cursors 
        x reduce to one method
        x instead of calling BtreeIndex::uncouple_cursor in PageManager
            (and others), the function could be moved "up" in the call tree
            into the relevant Btree modules
        x same for BtreeIndex::free_page_extkeys
    x clean up Cursor interface
    x Page::add_cursor, Page::remove_cursor:
        x move to BtreeCursor
        x try to merge with couple(), uncouple(); the following functions
            should exist:
            x set_to_nil()
            x get_state() -> nil | coupled | uncoupled
            x uncouple_from_page()
            x couple_to_page()
            x get_coupled_key(&page, &slot, &dupe_id)
            x get_uncoupled_key()

x clean up BtreeCursor - there still are many TODOs

x Environment::get_incremented_lsn should return void

x Rewrite Cursor::is_nil: fix TODOs, do not allow what==0

x Review Cursor documentation in cursor.h, btree_cursor.h, txn_cursor.h

x Refactor TxnCursor - similar to BtreeCuror
    x in destructor: assert that cursor is nil (do the same in ~BtreeCursor)

x clean up btree.h
    x clean up src/btree_check.cc
    x clean up src/btree_erase.cc
    x clean up src/btree_find.cc
    x clean up src/btree_insert.cc
    x clean up btree.h, remove TODOs
        x descriptor: consolidate setters into a single function 
    x clean up src/btree_node.h
    x clean up src/btree_key.h
    x clean up src/btree_key.cc
    x clean up src/btree_stats.h
    x clean up src/btree_stats.cc
    x clean up src/btree_enum.cc
        x use C++ object instead of generic callback function; users can
            derive from this object
        x move enumerate API to separate header file
    x review usage of Database::get_btree_index - should be protected?

x metrics: memory allocations currently ignore operator new/delete

x refactoring of page.h, page.cc

x reduce the file size if freelist adds page at end of file
    x bool Freelist::is_free(ham_u64_t address, ham_size_t size);
        x tests
    x loop through each page from end to beginning; if page is free: cut off
        the file
        x then truncate the file ("reclaim space")
    x only do this in ham_env_close
    x attention: if a file is truncated then recovery can re-create pages
        that are "outside" of the file boundaries! therefore only
        do this if the log is empty!
    x can be disabled with an (undocumented) flag (HAM_DISABLE_RECLAIM)
    x tests, esp. with reopen, is_free(), freelist allocs at end of file
    x no need to have code checking READ_ONLY - this can never happen
    x check the TODOs - there is at least one that needs fixing
    x verify correctness regarding logging/recovery - the modified freelist
        pages have to be logged before they're flushed (or just flush
        them directly after the modification?)
        x add them to the changeset
        x and flush the changeset when done
        x or flush immediately to disk if logging is disabled
    x split is_free_page to reclaim_page, is_page_free
    x do general refactoring of freelist.h, freelist.cc - remove macros etc
    x rename allocated_bits to free_bits
    x add to changelog

x if a btree page is deleted in btree_erase then the page is not moved to the
    freelist - correct? if yes, fix it
    -> no, everything's good

x page_size and pagesize are used inconsistently; use only one!

x introduce PageManager::close(), split PageManager-destructor,
    otherwise we can't catch the return values

x clean up Environment class
    x move the EnvironmentHeader into a separate module, encapsulating access
        -> class EnvironmentHeader
        -> struct PBtreeDescriptor -> PDatabaseHeader
        x header page access
        x encapsulate configuration access
        x a proxy for retrieving and/or caching the configuration values
    x merge changeset->add and env->set_dirty into a single call
        x Environment::mark_header_page_dirty(Page *, bool) -> void
    x remove the TODOs
    x make sure encryption is not allowed w/ remote a environment
        (or document that it's ignored - same about set_log_dir)
    x make EnvironmentHeader::get_max_databases() private
    x split into multiple files

x get rid of internal_fwd_decl.h

x is the recovery working if there's a crash while the journal is applied?
    -> no, it seems not, because it's disabled. There's actually no reason
        to disable the log, only the journal should be disabled!
    x disable journal while recovery is proceeding
    x run recovery tests

x journal.cc: use ByteArray during recovery/iterating

x log.cc: use ByteArray during recovery/iterating

x rename btree.h/.cc to btree_index.h/.cc

x release-v2.sh
    x test build with disabled AES, add this to the release process
        x check with "ldd", there must not be a dependency to libcrypto!
    x test build with disabled remote, add this to the release process
        x check with "ldd", there must not be a dependency to libuv!
    x test build with disabled tcmalloc, add this to the release process
        x fix issue #26
        x check with "ldd", there must not be a dependency to libtcmalloc_minimal!
    x move "diff" to the end, just warn if the files are different
    x tools-tests are failing
    x improve release process automization; the result of release-v2.sh
        are the following files:
        x tar-ball
        x the README
        x the documentation
        x the Changelog
        x the release notes (a template)

x disable reclaim space on Win32 if mmap is used

x src/config.h: always assume little endian, if nothing else is specified.
    x config.h sets WORDS_BIGENDIAN (for MacOS)
    x win32: remove HAM_LITTLE_ENDIAN from solution files
    x change in README

x issue #25: fix tcmalloc build on MacOS

x add client/server testing to monster testsuite
    x also to performance tests

x improve client/server performance
    currently client/server is 10 times slower than standalone; can we improve
    this, i.e. by using keepalive/open connections?
    x configure.in: remove --diable-server, always use --diable-remote
    x remove mongoose
    x check for libuv in configure.in
    x rewrite server side with libuv
        x server1 should compile and run
        x read_cb must use one ByteArray *per client*
        x accept() must allocate client structure
        x close_cb must release client structure
        x use uv_async_send for ham_srv_add_env
        x then continue with dispatch()
    x in on_read_data(): need a way to get the ham_srv_t structure AND
        the ByteArray buffer
    x handles:
        ham_srv_t stores these tables:
        - handles for environments
        - handles for databases
        - handles for transactions
        - handles for cursors
        - all of them are std::vector< Handle<X> >
            - Handle stores handle, X * (and later maybe even timestamps)
        - handle & 0xffff0000 verweisen auf index i.d. tabelle
        - handle & 0x00001111 ist ein counter
    x handle_connect: needs to send env-path and return env-handle
        x implement in server
        x implement in client
            os_posix.cc: socket-funktionen implementieren
            x server
            x client
        x implement disconnect as well
    x implement all other requests
    x Remote/getEnvParamsTest is still failing
    x remove debug output
    x run valgrind tests
    x remove references to access.log, error.log from the configuration file
        x also in hamzilla
    x reduce memory allocation when packing/unpacking requests
    x run server1/client1 with 10000 keys, then run client1 with a
        local database and compare the performance -> not much better
        than before
    x revert changes in client1, server1
    x run a test with hamzilla
    x port to win32
    x currently it's not allowed to have multiple clients opening the same
        database
        x in handle_db_open: return the open handle if it already is open
    x combining multiple transactions fails in a remote setup:
        ./test --enable-remote --use-transactions=5 --num-threads=5 ../../testfiles/1/01.tst
      ASSERT FAILED in file env.cc, line 53:
        "!"not yet implemented""
        problem: unlike the LocalEnvironment, transactions are not "flushed"
            but simply removed from the linked list, and this is not yet
            implemented.
        Either "flush" them or fix the linked list implementation.
    x unittest/valgrind.txt -> check memory leaks
    x unittest/valgrind.txt -> has warnings
        x CursorFindRequest: sends Record structure, but boolean flag 
            should be enough
        x same for CursorMoveRequest
    x test darwin/MacOS compilation

x fix java compiler warnings

o remote code crashes on win32

. java-test fails on a slower machine (race cond. in finalize()?)
    -> this is just a test issue

. run a performance test clang++ vs g++

------------------- release 2.1.2 -----------------------------------------




o rewrite configure.in; look at libuv for a good sample
        x also for bootstrap.sh
    x rename to configure.ac
    o also for monster tests
    o test on MacOS (tcmalloc must be disabled!)

o remove libjson, use boost::property_tree instead!

. review/rewrite/refactor Transaction class
    keep in mind that sooner or later the BtreeNode will expect template
    arguments; can we do something similar with the TransactionNode?
    x try to get the methods/design analoguous to the Btree - no, that
        does not make too much sense
    x document the tree structure in the header file
    x refactor the code
    o split into multiple files
    o try to cleanup the flow; move more code from db.cc to txn.cc
    . each Transaction should have its own PoolAllocator (based on ByteArray);
        when deleting the whole structure, only the PoolAllocator is freed
        o only do this if it releasing this memory turns out to cost
            performance
        o problem: a realloc() will not always work because it might move
            the allocated memory, and all existing pointers would be invalid 

o pre-allocate index; 1.10.x had this as an experimental feature
    o see roadmap document for more information
    o run a performance test/prototype if this is worth the effort
    o this feature is *per database*
    o Freelist::alloc_area_impl has a parameter "lower_bounds_index" which
        is currently not used. For allocations in a reserved area it could
        be set to the lower bound of this area. For other allocations it
        could be set to the upper bound (thus exceeding this area).
    o calculate number of reqd pages based on estimated keys from the user
    o needs freelist hints to retrieve the next possible
        free page *adjacent to* the previous index page
    o make sure that this is not reverted when "reduce file size" feature
        (above) is enabled
    o try to batch allocations; when new pages are required then don't just
        allocate one but multiple pages

o collect file format incompatibilities
    o for the new Btree code
    o persistent freelist statistics
    o persistent freelist payload
    o page header
    o get rid of the statistics-structures
    o reduce the PBlobHeader (remove flags, alloc_size)
    o what else?

o prepare btree rewrite; the goal is to move all node-specific operations
    into the node itself, and ultimately to get rid of BtreeIndex::compare

    o analyze node; move all node operations to the node itself
        o PBtreeNode::get_key()
        o find(key) -> position || kNotFound (== -1)
            -> BtreeIndex::get_slot
               (rename to get_position_in_page; returns position or kNotFound)
        o insert(key, RecordIdProxy) -> Proxy creates RecordId if insert is
                successful
            -> needs_split() -> bool
            -> split(Page *newpage, int pivot, bool internal)
            -> insert(key, record_proxy, flags = HINT_PREPEND, HINT_APPEND,
                        OVERWRITE, DUPLICATE) -> {slot, duplicate_id}
            -> append_no_split(key, record_proxy) -> {slot, duplicate_id}
            -> prepend_no_split(key, record_proxy) -> {slot, duplicate_id}
        o erase
            o remove_entry(Page, slot) -> erase_from_page(Page, slot)
            o copy_key(SrcPage, SrcSlot, DestPage, DestSlot)
            o replace_key(SrcPage, SrcSlot, DestPage, DestSlot)
            o shift
            o merge
        o what else?
            o Node::initialize() - called when a new page is allocated
            o need an "iterator" concept where it is possible to get the
              previous or the next key (for approx. matching and cursors)
            o need to change the PBtreeKey class - it might not have a size!
    o suggest new code flow
        o Abstract baseclass BtreeNodeProxy, which is then derived and
            implemented with template parameters. The generated pointer is
            stored in the Page object (make sure it's deleted when the page
            is moved to the freelist!). The BtreeNodeProxy will have all the
            additional logic for the PBtreeNode (which will not be modified).
        o Need a factory for BtreeNodeProxy objects
        o start by rewriting BtreeCheckIntegrityAction; use a template function
            to compare keys (which uses the pointer function internally)
            o add UINT32 keys (HAM_PARAM_KEY_TYPE == HAM_TYPE_UINT32) and
                implement a new Comparator
            o implement the BtreeNodeProxy class
                o needs get_position, get_key
            o implement the BtreeKeyProxy class
                o for variable size (existing) keys
                o for fixed size keys (uint32, uint64...)
        o then rewrite BtreeEnumAction

o start with the Btree rewrite; btree nodes are accepting template parameters
    and policies. The default parameter uses the callback function provided
    by the user. There are many notes on paper flying around - collect
    and consolidate them first.
    o support existing callbacks - everything should work as advertised
    o support binary search and linear search through a node
    o support POD types: int8, uint8, int16, uint16, int32, uint32, int64,
        uint64, float, double, fixed length blobs, fixed length strings (?)
        (w/o duplicates and extended keys - they always enforce the
        default type based on the callback)
    ------- release -------
    o support variable length types, use linear search (with a skiplist)
        for strings (strcmp), blobs (memcmp)
    o replace extended keys; store them in the leaf unless they're TOO big
        (then either use an overflow area or refuse to store them i.e. if
        they are > 20% of the page - better refuse, then we can also get
        rid of the error code that can be returned by the compare function)
    ------- release -------
    o replace duplicate keys; this will be difficult because it requires
        rewriting the Cursor consolidation flow
    ------- release -------
    o optionally store fixed length record in leaf (not in internal pages!)
    ------- release -------











. also remove locking from C# and Java APIs

. BtreeCursor: use memory arena for uncoupling the key
    -> better wait till extended keys are gone

o is the recovery working if there's a crash during ham_db_close
    or ham_env_close?





------------------- idea soup ---------------------------------------------

o allow transactions w/o journal

o allow transactions w/o recovery

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o when flushing the Changeset: batch ALL changes for the WHOLE transaction,
    then flush all of them together. This way we can "merge" multiple changes
    for the same page.
    Also review the whole flush process - when not to log etc.
    - only 1 page affected: no need to log it because it is idempotent
    - freelist pages are always idempotent
    - more than 1 index page? not idempotent (most likely)
    - more than 1 blob page? not idempotent (maybe)
    o define a few benchmarks
    o be careful: if N operations are modifying the same changelog, and
        then #N+1 aborts then the aborting operation must NOT clear the
        changelog!

o A new transactional mode: read-only transactions can run "in the past" - only
    on committed transactions. therefore they avoid conflicts and will always
    succeed.

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset, and batch-commit multiple commits? that way we would avoid the
    frequent syncs and performance would be improved
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

. track additional metrics
    o cache misses
    o cache hits
    o ...

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurÃ¼ckgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the file, not
    to the log. the log will only contain the rid.
    -> or: make this the default; call the new flag HAM_TXN_MAYBE_WILL_ABORT
    o in case of an abort: move the record to the freelist
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o ham_get_count: could be atomically updated with every journal entry

