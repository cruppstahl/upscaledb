I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x win32: get rid of boost_thread

x boost: configure script should make sure that only boost v 1.46 (or newer)
    is accepted
    -> also test with older versions, but 1.33 definitely does not work
    issue #17: https://github.com/cruppstahl/hamsterdb/issues/17

x metrics: add extkey_cache:hits, :misses

x AES encryption
    x create a test program which encrypts/decrypts data (cbc)
        http://saju.net.in/code/misc/openssl_aes.c.txt
    x ./configure: enable aes by default if -lcrypto is available
    x ./configure: add new option "--disable-encryption"
    x move prototype to .cc file
    x create header file documentation; HAM_PARAM_ENCRYPTION_KEY is a
        16byte array with the key
    x ham_env_create: new option HAM_PARAM_ENCRYPTION_KEY enables encryption
        x do not allow if in-memory 
            x unittest
        x disable mmap if encryption is enabled
            x unittest
    x ham_env_open: new option HAM_PARAM_ENCRYPTION_KEY
        x add unittests for create/open, test good and bad keys
        x disable mmap if encryption is enabled
            x unittest
    x disable direct I/O
    x encrypt/decrypt pages
        x cbc-encrypted with page-id as salt
        x need tests w/ reopen, inserts (growing size, 1 - 512 bytes)
    x encrypt/decrypt the log (everything is already padded)
        x do not use salt
        x need tests w/ recovery
        x also test in recovery.pl
    x add to monster tests
    x extend the Windows build

x clean up Database class
    x split into multiple files
    x remove the TODOs
    x refactor, reformat if necessary
    x db_local.cc has many static functions; remove them

x clean up Cursors
    x different definitions of Page::uncouple_cursor,
        BtreeIndex::uncouple_cursor, btree_uncouple_cursors 
        x reduce to one method
        x instead of calling BtreeIndex::uncouple_cursor in PageManager
            (and others), the function could be moved "up" in the call tree
            into the relevant Btree modules
        x same for BtreeIndex::free_page_extkeys
    x clean up Cursor interface
    x Page::add_cursor, Page::remove_cursor:
        x move to BtreeCursor
        x try to merge with couple(), uncouple(); the following functions
            should exist:
            x set_to_nil()
            x get_state() -> nil | coupled | uncoupled
            x uncouple_from_page()
            x couple_to_page()
            x get_coupled_key(&page, &slot, &dupe_id)
            x get_uncoupled_key()

x clean up BtreeCursor - there still are many TODOs

x Environment::get_incremented_lsn should return void

x Rewrite Cursor::is_nil: fix TODOs, do not allow what==0

x Review Cursor documentation in cursor.h, btree_cursor.h, txn_cursor.h

x Refactor TxnCursor - similar to BtreeCuror
    x in destructor: assert that cursor is nil (do the same in ~BtreeCursor)

x clean up btree.h
    x clean up src/btree_check.cc
    x clean up src/btree_erase.cc
    x clean up src/btree_find.cc
    x clean up src/btree_insert.cc
    x clean up btree.h, remove TODOs
        x descriptor: consolidate setters into a single function 
    x clean up src/btree_node.h
    x clean up src/btree_key.h
    x clean up src/btree_key.cc
    x clean up src/btree_stats.h
    x clean up src/btree_stats.cc
    x clean up src/btree_enum.cc
        x use C++ object instead of generic callback function; users can
            derive from this object
        x move enumerate API to separate header file
    x review usage of Database::get_btree_index - should be protected?

x metrics: memory allocations currently ignore operator new/delete

x refactoring of page.h, page.cc

x reduce the file size if freelist adds page at end of file
    x bool Freelist::is_free(ham_u64_t address, ham_size_t size);
        x tests
    x loop through each page from end to beginning; if page is free: cut off
        the file
        x then truncate the file ("reclaim space")
    x only do this in ham_env_close
    x attention: if a file is truncated then recovery can re-create pages
        that are "outside" of the file boundaries! therefore only
        do this if the log is empty!
    x can be disabled with an (undocumented) flag (HAM_DISABLE_RECLAIM)
    x tests, esp. with reopen, is_free(), freelist allocs at end of file
    x no need to have code checking READ_ONLY - this can never happen
    x check the TODOs - there is at least one that needs fixing
    x verify correctness regarding logging/recovery - the modified freelist
        pages have to be logged before they're flushed (or just flush
        them directly after the modification?)
        x add them to the changeset
        x and flush the changeset when done
        x or flush immediately to disk if logging is disabled
    x split is_free_page to reclaim_page, is_page_free
    x do general refactoring of freelist.h, freelist.cc - remove macros etc
    x rename allocated_bits to free_bits
    x add to changelog

x if a btree page is deleted in btree_erase then the page is not moved to the
    freelist - correct? if yes, fix it
    -> no, everything's good

x page_size and pagesize are used inconsistently; use only one!

o run a performance test clang++ vs g++

o improve client/server performance
    currently client/server is 10 times slower than standalone; can we improve
    this, i.e. by using keepalive/open connections?
    o configure.in: remove --diable-server, always use --diable-remote
    o create/define a benchmark (i.e. based on client1.c/server1.c sample)
    o use libuv on server side, get rid of mongoose
        http://nikhilm.github.io/uvbook/networking.html
    o use libuv on client side, get rid of libcurl
    o test build with --disable-remote, add this to the release process
    . use Pickle module, get rid of protocol buffers (or better leave for now?)

. clean up Environment class
    o split into multiple files
    o remove the TODOs

o release-v2.sh
    o test build with disabled AES, add this to the release process
    o test build with disabled remote, add this to the release process

. when flushing the Changeset: batch ALL changes for the WHOLE transaction,
    then flush all of them together. This way we can "merge" multiple changes
    for the same page.
    Also review the whole flush process - when not to log etc.
    - only 1 page affected: no need to log it because it is idempotent
    - freelist pages are always idempotent
    - more than 1 index page? not idempotent (most likely)
    - more than 1 blob page? not idempotent (maybe)
    o define a few benchmarks

. pre-allocate index; 2.0.0 had this as an experimental feature
    o see roadmap document for more information
    o run a performance test/prototype if this is worth the effort
    o this feature is *per database*
    o Freelist::alloc_area_impl has a parameter "lower_bounds_index" which
        is currently not used. For allocations in a reserved area it could
        be set to the lower bound of this area. For other allocations it
        could be set to the upper bound (thus exceeding this area).
    o calculate number of reqd pages based on estimated keys from the user
    o needs freelist hints to retrieve the next possible
        free page *adjacent to* the previous index page
    o make sure that this is not reverted when "reduce file size" feature
        (above) is enabled
    o try to batch allocations; when new pages are required then don't just
        allocate one but multiple pages

------------------- release 2.1.2 -----------------------------------------











o collect file format incompatibilities
    o for the new Btree code
    o persistent freelist statistics
    o persistent freelist payload
    o page header
    o get rid of the statistics-structures
    o reduce the PBlobHeader (remove flags, alloc_size)
    o what else?

o split Transaction into local and remote class (really?)
    hamsterdb.cc directly calls into Transaction class instead of Environment
    o create PoolAllocator based on ByteArray
    o keep in mind that sooner or later the BtreeNode will expect
        template arguments; can we do something similar with the
        TransactionNode?
    o try to cleanup the flow; move more code from db.cc to txn.cc,
        reorg TransactionIndex similar to BtreeIndex
    o try to get the methods/design analoguous to the Btree
    o TransactionIndex:
        o TransactionIndex: use std::set<OperationNode> instead of rb.h?? Not
            sure if this is worth the troubles
        x check how/if std::multimap can replace rb.h - yes, seems to work
        o replaces the TransactionTree
        o one TransactionIndex per Database (always created)
        o txn_opnode_t -> TransactionOperation
        o try to move code from db.cc into TransactionIndex, i.e. to check
            conflicts etc
    o try to replace some of the linked lists with boost::intrusive_list
    o document the tree structure in the header file

o split Cursor into local and remote class (really?)
    o hamsterdb: directly call into Cursor class (instead of Database)

o start with the Btree rewrite; btree nodes are accepting template parameters
    and policies. The default parameter uses the callback function provided
    by the user. There are many notes on paper flying around - collect
    and consolidate them first.
    o support existing callbacks - everything should work as advertised
    o support binary search and linear search through a node
    o support POD types: int8, uint8, int16, uint16, int32, uint32, int64,
        uint64, float, double, fixed length blobs, fixed length strings (?)
        (w/o duplicates - duplicates always enforce the default type)
    o support variable length types, use linear search (with a skiplist)
    ------- release -------
    o replace extended keys; store them in the leaf unless they're TOO big
        (then either use an overflow area or refuse to store them i.e. if
        they are > 20% of the page)
    ------- release -------
    o replace duplicate keys; this will be difficult because it requires
        rewriting the Cursor consolidation flow
    ------- release -------
    o optionally store fixed length record in leaf
    ------- release -------











. also remove locking from C# and Java APIs

. BtreeCursor: use memory arena for uncoupling the key
    -> better wait till extended keys are gone

o is the recovery working if there's a crash during ham_db_close
    or ham_env_close?

o allow transactions w/o journal

o allow transactions w/o recovery

o move the whole configuration (key sizes, parameters, page size, etc) into a
    separate class which is instantiated by the env

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o fully (!) automize the whole release process for unix; the result (on
    success) are the following files:
    o tar-ball
    o the README
    o the documentation
    o the Changelog
    o the release notes (a template)
    o move monster test to ec2?
    o the output of the monster tests and the performance test
    o windows-packages

o update documentation
    x in header file
    o in the wiki
        o don't forget to list all functions that are currently disabled
            w/ txn's -> sorting dupes, approx. matching, ...
        o transactional behavior/conflicts of duplicate keys
    o in the wiki: start with internal documentation
        o transactions
        o architecture
        o btree
        o journal/log
        o cache
        o I/O
        o unittests
        o cursor(s)
        o monstertests - how to use them?





------------------- idea soup ---------------------------------------------

o A new transactional mode: read-only transactions can run "in the past" - only
    on committed transactions. therefore they avoid conflicts and will always
    succeed.

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset, and batch-commit multiple commits? that way we would avoid the
    frequent syncs and performance would be improved
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

. track additional metrics
    o cache misses
    o cache hits
    o ...

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurÃ¼ckgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the file, not
    to the log. the log will only contain the rid.
    o in case of an abort: move the record to the freelist
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o ham_get_count: could be atomically updated with every journal entry

